from sentence_transformers import SentenceTransformer
import faiss
from transformers import pipeline

# Step 1: Building a Knowledge Base. Each line functions as a document
input_document = [
    "OpenAI is an artificial intelligence research laboratory.", #Document1
    "The CEO of OpenAI is Sam Altman.",                          #Document2
    "OpenAI developed models like GPT and DALL-E.",              #Document3
    "Sam Altman is a renowned entrepreneur in the AI industry."  #Document4
]

# Step 2: Encoding the Documents
model = SentenceTransformer('all-MiniLM-L6-v2')
document_embeddings = model.encode(input_document)

# Step 3: Set Up FAISS for Retrieval
dimension = document_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(document_embeddings)

# Step 4: Retrieve Relevant Documents
def retrieve(query, top_k=2):
    query_embedding = model.encode([query])
    distances, indices = index.search(query_embedding, top_k)
    return [input_document[i] for i in indices[0]]

# Step 5: Generate an Answer Using a Generator
generator = pipeline("text2text-generation", model="google/flan-t5-small")

def rag_pipeline(query):
    # Retrieve documents
    retrieved_docs = retrieve(query)
    context = " ".join(retrieved_docs)
    
    # Combine query with context for generation
    prompt = f"Context: {context}\n\nQuestion: {query}\nAnswer:"
    response = generator(prompt, max_length=50, num_return_sequences=1)
    return response[0]['generated_text']

# Test the RAG Pipeline
query = "Who is the CEO of OpenAI?"
print("Query:", query)
print("Answer:", rag_pipeline(query))